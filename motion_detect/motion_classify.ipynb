{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import grid_search\n",
    "from sklearn import decomposition\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motionloc = 'C:/Users/Valued Customer/Desktop/motion_feature.csv'\n",
    "nomotionloc = 'C:/Users/Valued Customer/Desktop/nomotion_feature.csv'\n",
    "motion = pd.read_csv(motionloc, header=None,skip_blank_lines=True) # load whole table, row 22 is NA\n",
    "nomotion = pd.read_csv(nomotionloc, header=None,skip_blank_lines=True)\n",
    "motion_data = motion.ix[1:,2:]  # column 2-end are features, row 0 is column name\n",
    "nomotion_data = nomotion.ix[1:,2:]\n",
    "motion_class = np.empty(len(motion)-1) \n",
    "motion_class [:] = 1 #\n",
    "#motion.ix[1:,7] # column 7 is class\n",
    "nomotion_class = np.empty(len(nomotion)-1) \n",
    "nomotion_class [:] = 0 \n",
    "#nomotion.ix[1:,7]\n",
    "x=motion_data[:].append(nomotion_data[:],ignore_index = True) # motion: 0-35 Baylor, non motion: 0-50 Baylor\n",
    "x=x.astype('float64') # convert string to float\n",
    "y=pd.concat([pd.DataFrame(motion_class[:]),pd.DataFrame(nomotion_class[:])],ignore_index = True)\n",
    "for i in range(len(y)):\n",
    "    y.ix[i]=y.ix[i].astype('category') # convert string to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=cv.train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_scaled = preprocessing.scale(x_train)\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_test_scaled= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_scaled=pd.DataFrame(x_train_scaled)\n",
    "# data_scaled['class']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_all=pd.DataFrame(x_train_scaled).append(pd.DataFrame(x_test_scaled))\n",
    "# x_scaled=pd.DataFrame(x_train_scaled).append(pd.DataFrame(x_test_scaled))\n",
    "# data_all['class']=y\n",
    "# _=data_all.boxplot(by='class')\n",
    "# _=data_all.groupby('class').boxplot() \n",
    "# _=scatter_matrix(x, alpha=0.2, figsize=(6, 6))#, diagonal='kde')\n",
    "# _=data_all.hist()\n",
    "\n",
    "# correlations = x_scaled.corr()\n",
    "# # plot correlation matrix\n",
    "# # machine learning mastery with python Chap 6.\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "# fig.colorbar(cax)\n",
    "# _=plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.706363636364+/-0.155068633165\n",
      "QDA: accuracy 0.766363636364+/-0.100251749227\n",
      "logistic regression: accuracy 0.78+/-0.0849939229719\n",
      "random forest: accuracy 0.800454545455+/-0.0613366944222\n",
      "SVC: accuracy 0.805+/-0.0593508269627\n",
      "KNN: accuracy 0.790454545455+/-0.0516844366491\n"
     ]
    }
   ],
   "source": [
    "names=['LDA','QDA','logistic regression','random forest','SVC','KNN']\n",
    "classifiers=[LinearDiscriminantAnalysis(),\n",
    "             QuadraticDiscriminantAnalysis(),\n",
    "             LogisticRegression(),\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=3, max_features=1),\n",
    "             SVC(gamma=2, C=1),\n",
    "             KNeighborsClassifier(3)]\n",
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_train_scaled, y_train[0], cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Classifier with first 5 of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.701818181818+/-0.137753522851\n",
      "QDA: accuracy 0.628181818182+/-0.11609699564\n",
      "logistic regression: accuracy 0.769090909091+/-0.113632727215\n",
      "random forest: accuracy 0.769090909091+/-0.104876944815\n",
      "SVC: accuracy 0.814090909091+/-0.0632929043064\n",
      "KNN: accuracy 0.761363636364+/-0.0861300669322\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_train_scaled[:,:5], y_train[0], cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Since SVC has the best result, grid search for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77426368268112777"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas = np.logspace(-4, 1, 10)\n",
    "svc = SVC()\n",
    "clf = grid_search.GridSearchCV(estimator=svc, param_grid=dict(gamma=gammas),n_jobs=-1)\n",
    "clf.fit(x_train_scaled, y_train[0]) \n",
    "best_gamma=clf.best_estimator_.gamma\n",
    "best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83363636363636373"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cross_validation.cross_val_score(SVC(gamma=best_gamma), x_train_scaled[:,:], y_train[0], cv=10,scoring='accuracy')\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold() #threshold=(.8 * (1 - .8))\n",
    "sel.fit(x_train_scaled)\n",
    "idx=sel.get_support(indices=True)\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "11.2831677\n",
      "2.53735688786\n",
      "0.783275533127\n",
      "0.191859869295\n",
      "0.150228184456\n",
      "0.0316179753283\n",
      "0.0160958952485\n",
      "0.00457959269924\n"
     ]
    }
   ],
   "source": [
    "cor_mat = np.corrcoef(x_train_scaled.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat)\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs[0:8]: ### show top 8\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Valued Customer\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83363636363636373"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=5) # from varirance-explained above, n=3\n",
    "pca.fit(x_train_scaled)\n",
    "train_xPCA=pca.transform(x_train_scaled)\n",
    "test_xPCA=pca.transform(y_test) #PCA both trainging and testing data\n",
    "# random forest classification\n",
    "clf = SVC(gamma=best_gamma)\n",
    "clf.fit(train_xPCA, y_train)\n",
    "output=clf.predict(test_xPCA)\n",
    "scores = cv.cross_val_score(clf, train_xPCA, y_train[0], cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal: one class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outliers_fraction = 0.1 # assume % are outliers\n",
    "clf=svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05, kernel=\"rbf\", gamma=0.1) # nu=0.1\n",
    "clf.fit(x_train_scaled)\n",
    "y_pred = clf.decision_function(x_train_scaled).ravel()\n",
    "threshold = stats.scoreatpercentile(y_pred,100 * outliers_fraction)\n",
    "id_OR = y_pred > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.767234262126+/-0.107402641242\n",
      "QDA: accuracy 0.742810457516+/-0.0988927190105\n",
      "logistic regression: accuracy 0.778706570347+/-0.076754728516\n",
      "random forest: accuracy 0.784588923289+/-0.0650992956551\n",
      "SVC: accuracy 0.805933952528+/-0.0527682163722\n",
      "KNN: accuracy 0.783969728242+/-0.0515148943751\n"
     ]
    }
   ],
   "source": [
    "x_OR = x_train_scaled[id_OR,:] # training data outlier removed\n",
    "y_OR = y_train[id_OR]\n",
    "names=['LDA','QDA','logistic regression','random forest','SVC','KNN']\n",
    "classifiers=[LinearDiscriminantAnalysis(),\n",
    "             QuadraticDiscriminantAnalysis(),\n",
    "             LogisticRegression(),\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=3, max_features=1),\n",
    "             SVC(gamma=2, C=1),\n",
    "             KNeighborsClassifier(3)]\n",
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_OR, y_OR[0], cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + one class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05 # assume % are outliers\n",
    "clf=svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05, kernel=\"rbf\", gamma=0.1) # nu=0.1\n",
    "clf.fit(train_xPCA)\n",
    "y_pred = clf.decision_function(train_xPCA).ravel()\n",
    "threshold = stats.scoreatpercentile(y_pred,100 * outliers_fraction)\n",
    "id_PCAOR = y_pred > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.753558897243+/-0.123983890893\n",
      "QDA: accuracy 0.728796992481+/-0.104012332009\n",
      "logistic regression: accuracy 0.763558897243+/-0.0929882284787\n",
      "random forest: accuracy 0.774110275689+/-0.0659010439565\n",
      "SVC: accuracy 0.82045112782+/-0.0659973514939\n",
      "KNN: accuracy 0.768847117794+/-0.063123304766\n"
     ]
    }
   ],
   "source": [
    "x_PCAOR = train_xPCA[id_PCAOR,:] # training data outlier removed\n",
    "y_PCAOR = y_train[id_PCAOR]\n",
    "names=['LDA','QDA','logistic regression','random forest','SVC','KNN']\n",
    "classifiers=[LinearDiscriminantAnalysis(),\n",
    "             QuadraticDiscriminantAnalysis(),\n",
    "             LogisticRegression(),\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=3, max_features=1),\n",
    "             SVC(gamma=2, C=1),\n",
    "             KNeighborsClassifier(3)]\n",
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_PCAOR, y_PCAOR[0], cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + distance bases outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a center for motion and a center for non motion\n",
    "data =  pd.DataFrame(train_xPCA)\n",
    "data['class'] = y_train.values\n",
    "# data.columns = ['PCA1','PCA2','PCA3','PCA4','PCA5','class']\n",
    "m=data.loc[data['class']== 1]\n",
    "nm=data.loc[data['class']== 0]\n",
    "m_center = m.ix[:,0:5].mean(axis = 0) # motoin cetner, column mean gives center\n",
    "nm_center = nm.ix[:,0:5].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_L = m_center.shape[0]\n",
    "nm_L = nm_center.shape[0]\n",
    "\n",
    "#### Euclidean distance\n",
    "m_dis = cdist(m.ix[:,0:5], m_center.reshape(-1,m_L)) # Euclidean distance to the center\n",
    "nm_dis = cdist(nm.ix[:,0:5], nm_center.reshape(-1,nm_L))\n",
    "\n",
    "# #### mahalonobis distance\n",
    "# dis = []\n",
    "# cov_x = np.cov(train_xPCA, rowvar=0)\n",
    "# invcov = np.linalg.inv(cov_x)\n",
    "# dis.append([mahalanobis(train_xPCA[i,:], center.reshape(-1,L), invcov) for i in range(train_xPCA.shape[0])])\n",
    "# dis = np.array(dis)\n",
    "# dis = dis.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_std = m_dis.std() # standard deviation of the distance\n",
    "nm_std = nm_dis.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951219512195\n"
     ]
    }
   ],
   "source": [
    "idm_PCAdOR =(m_dis < m_dis.mean()+1*m_std) * (m_dis.mean()-1*m_std <m_dis) # outliers are 2*std away from the center\n",
    "print(sum(sum(idm_PCAdOR))/float(m_dis.shape[0])) # percent of outliers\n",
    "idm_PCAdOR = idm_PCAdOR.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686746987952\n"
     ]
    }
   ],
   "source": [
    "idnm_PCAdOR =(nm_dis < nm_dis.mean()+1*nm_std) * (nm_dis.mean()-1*nm_std <nm_dis) # outliers are 2*std away from the center\n",
    "print(sum(sum(idnm_PCAdOR))/float(nm_dis.shape[0])) # percent of outliers\n",
    "idnm_PCAdOR = idnm_PCAdOR.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.788194444444+/-0.0983687357803\n",
      "QDA: accuracy 0.80625+/-0.0878657479368\n",
      "logistic regression: accuracy 0.829166666667+/-0.0845512847512\n",
      "random forest: accuracy 0.741666666667+/-0.085210342501\n",
      "SVC: accuracy 0.850694444444+/-0.050580160374\n",
      "KNN: accuracy 0.809027777778+/-0.0933892235105\n"
     ]
    }
   ],
   "source": [
    "x_PCAdOR =pd.concat([m.ix[idm_PCAdOR,0:5], nm.ix[idnm_PCAdOR,0:5]],ignore_index = True) # training data outlier removed\n",
    "y_PCAdOR =pd.concat([m['class'].ix[idm_PCAdOR,],nm['class'].ix[idnm_PCAdOR]],ignore_index = True)\n",
    "y_PCAdOR = y_PCAdOR.astype('category')\n",
    "names=['LDA','QDA','logistic regression','random forest','SVC','KNN']\n",
    "classifiers=[LinearDiscriminantAnalysis(),\n",
    "             QuadraticDiscriminantAnalysis(),\n",
    "             LogisticRegression(),\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=3, max_features=1),\n",
    "             SVC(gamma=2, C=1),\n",
    "             KNeighborsClassifier(3)]\n",
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_PCAdOR, y_PCAdOR, cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance based outlier removal on full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(x_train_scaled[:,:])\n",
    "data['class']=y_train.values\n",
    "data.columns=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m=data.loc[data['class']==1]\n",
    "m.columns=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','class']\n",
    "nm=data.loc[data['class']==0]\n",
    "nm.columns=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951219512195\n",
      "0.686746987952\n"
     ]
    }
   ],
   "source": [
    "m_center = m.ix[:,0:-1].mean(axis = 0) # motoin center, column mean gives center\n",
    "nm_center = nm.ix[:,0:-1].mean(axis = 0)\n",
    "m_L = m_center.shape[0]\n",
    "nm_L = nm_center.shape[0]\n",
    "\n",
    "#### Euclidean distance\n",
    "m_dis = cdist(m.ix[:,0:-1], m_center.reshape(-1,m_L)) # Euclidean distance to the center\n",
    "nm_dis = cdist(nm.ix[:,0:-1], nm_center.reshape(-1,nm_L))\n",
    "\n",
    "m_std = m_dis.std() # standard deviation of the distance\n",
    "nm_std = nm_dis.std()\n",
    "\n",
    "idm_PCAdOR =(m_dis < m_dis.mean()+1*m_std) * (m_dis.mean()-1*m_std <m_dis) # outliers are 2*std away from the center\n",
    "print(sum(sum(idm_PCAdOR))/float(m_dis.shape[0])) # percent of outliers\n",
    "idm_PCAdOR = idm_PCAdOR.ravel()\n",
    "\n",
    "idnm_PCAdOR =(nm_dis < nm_dis.mean()+1*nm_std) * (nm_dis.mean()-1*nm_std <nm_dis) # outliers are 2*std away from the center\n",
    "print(sum(sum(idnm_PCAdOR))/float(nm_dis.shape[0])) # percent of outliers\n",
    "idnm_PCAdOR = idnm_PCAdOR.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.788194444444+/-0.0983687357803\n",
      "QDA: accuracy 0.80625+/-0.0878657479368\n",
      "logistic regression: accuracy 0.829166666667+/-0.0845512847512\n",
      "random forest: accuracy 0.793055555556+/-0.0440082764382\n",
      "SVC: accuracy 0.850694444444+/-0.050580160374\n",
      "KNN: accuracy 0.809027777778+/-0.0933892235105\n"
     ]
    }
   ],
   "source": [
    "a=m.ix[idm_PCAdOR,0:-1]\n",
    "b=nm.ix[idnm_PCAdOR,0:-1]\n",
    "x_PCAdOR =pd.concat([a, b],ignore_index = True,axis=0) # training data outlier removed\n",
    "y_PCAdOR =pd.concat([m['class'].ix[idm_PCAdOR,],nm['class'].ix[idnm_PCAdOR]],ignore_index = True)\n",
    "names=['LDA','QDA','logistic regression','random forest','SVC','KNN']\n",
    "classifiers=[LinearDiscriminantAnalysis(),\n",
    "             QuadraticDiscriminantAnalysis(),\n",
    "             LogisticRegression(),\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=3, max_features=1),\n",
    "             SVC(gamma=2, C=1),\n",
    "             KNeighborsClassifier(3)]\n",
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_PCAdOR, y_PCAdOR, cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance based outlier removal on first 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(x_train_scaled[:,0:5])\n",
    "data['class']=y_train.values\n",
    "data.columns=['1','2','3','4','5','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=data.loc[data['class']==1]\n",
    "m.columns=['1','2','3','4','5','class']\n",
    "nm=data.loc[data['class']==0]\n",
    "nm.columns=['1','2','3','4','5','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934959349593\n",
      "0.927710843373\n"
     ]
    }
   ],
   "source": [
    "m_center = m.ix[:,0:-1].mean(axis = 0) # motoin center, column mean gives center\n",
    "nm_center = nm.ix[:,0:-1].mean(axis = 0)\n",
    "m_L = m_center.shape[0]\n",
    "nm_L = nm_center.shape[0]\n",
    "\n",
    "#### Euclidean distance\n",
    "m_dis = cdist(m.ix[:,0:-1], m_center.reshape(-1,m_L)) # Euclidean distance to the center\n",
    "nm_dis = cdist(nm.ix[:,0:-1], nm_center.reshape(-1,nm_L))\n",
    "\n",
    "m_std = m_dis.std() # standard deviation of the distance\n",
    "nm_std = nm_dis.std()\n",
    "\n",
    "idm_PCAdOR =(m_dis < m_dis.mean()+1*m_std) * (m_dis.mean()-1*m_std <m_dis) # outliers are 2*std away from the center\n",
    "print(sum(sum(idm_PCAdOR))/float(m_dis.shape[0])) # percent of outliers\n",
    "idm_PCAdOR = idm_PCAdOR.ravel()\n",
    "\n",
    "idnm_PCAdOR =(nm_dis < nm_dis.mean()+1.5*nm_std) * (nm_dis.mean()-1.5*nm_std <nm_dis) # outliers are 2*std away from the center\n",
    "print(sum(sum(idnm_PCAdOR))/float(nm_dis.shape[0])) # percent of outliers\n",
    "idnm_PCAdOR = idnm_PCAdOR.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: accuracy 0.75014619883+/-0.0934624092811\n",
      "QDA: accuracy 0.725964912281+/-0.118020244389\n",
      "logistic regression: accuracy 0.787894736842+/-0.0977793866512\n",
      "random forest: accuracy 0.781228070175+/-0.0516698685452\n",
      "SVC: accuracy 0.828421052632+/-0.063225245657\n",
      "KNN: accuracy 0.777894736842+/-0.0811351823864\n"
     ]
    }
   ],
   "source": [
    "a=m.ix[idm_PCAdOR,0:-1]\n",
    "b=nm.ix[idnm_PCAdOR,0:-1]\n",
    "x_PCAdOR =pd.concat([a, b],ignore_index = True,axis=0) # training data outlier removed\n",
    "y_PCAdOR =pd.concat([m['class'].ix[idm_PCAdOR,],nm['class'].ix[idnm_PCAdOR]],ignore_index = True)\n",
    "names=['LDA','QDA','logistic regression','random forest','SVC','KNN']\n",
    "classifiers=[LinearDiscriminantAnalysis(),\n",
    "             QuadraticDiscriminantAnalysis(),\n",
    "             LogisticRegression(),\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=3, max_features=1),\n",
    "             SVC(gamma=2, C=1),\n",
    "             KNeighborsClassifier(3)]\n",
    "for name, clf in zip(names,classifiers):\n",
    "    #clf.fit(x_train_scaled,y_train)\n",
    "    #print(clf.score(x_test_scaled,y_test))\n",
    "    score = cross_validation.cross_val_score(clf, x_PCAdOR, y_PCAdOR, cv=10,scoring='accuracy')\n",
    "    print'{}: accuracy {}+/-{}'.format(name,score.mean(),score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
